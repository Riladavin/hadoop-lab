version: "3"

services:
  namenode: # названием сервиса (контейнера), может быть любым
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8 # image для докера (определяет, что будет поддерживать в докере)
    container_name: namenode # имя контейнера
    restart: always # перезапускать ли контейнер в случае его остановки, будь то штатный выход или ошибка
#    mem_limit: 2g # лимит по используемой памяти
    ports: # порты, с которыми будет работать сервис (для обращения к сервису за пределами контейнера с помощью перенаправления указанных портов на порт компьютера (не докера))
      # формат записи <порт компьютера>:<порт контейнера>
      - 9870:9870 # порт для связи с localhost (http://localhost:9870/dfshealth.html#tab-overview) и datanode
    volumes: # связывание томов между запущенными контейнерами (куда будут сохраняться файлы, даже если контейнер будет удалён)
      # формат записи <имя тома>:<путь монтирования тома в контейнере>
      - hadoop:/hadoop/dfs/name # hadoop — имя тома, /hadoop/dfs/name — путь монтирования в контейнере
    environment: # переменные окружения для контейнера (разделитель — ',', а не '/')
      - CLUSTER_NAME=main_namenode # название кластера namenode
#     - HADOOP_HEAPSIZE=2048 # максимальный размер кучи для всех сервисов Hadoop (HDFS, YARN, MapReduce)
    env_file: # файл с переменными окружения, что будут использоваться в контейнере
      - ./hadoop.env # путь до файла
#    deploy: # настройки развёртывания и управления контейнером
#      resources: # настройки ресурсов контейнера
#        limits: # лимиты
#          memory: 5G # лимит по памяти для контейнера

  datanode_1: # названием сервиса (контейнера), может быть любым
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8 # image для докера (определяет, что будет поддерживать в докере)
    container_name: datanode_1 # имя контейнера
    restart: always # перезапускать ли контейнер в случае его остановки, будь то штатный выход или ошибка
    volumes: # связывание томов между запущенными контейнерами (куда будут сохраняться файлы, даже если контейнер будет удалён)
      # формат записи <имя тома>:<путь монтирования тома в контейнере>
      - hadoop:/hadoop/dfs/data_1 # hadoop — имя тома, /hadoop/dfs/data_1 — путь монтирования в контейнере
    environment: # переменные окружения для контейнера (разделитель — ',', а не '/')
      - SERVICE_PRECONDITION=namenode:9870 # связывание datanode с namenode по порту 9870
    env_file: # файл с переменными окружения, что будут использоваться в контейнере
      - ./hadoop.env # путь до файла

  spark-master: # названием сервиса (контейнера), может быть любым
    image: bde2020/spark-master:3.0.0-hadoop3.2 # image для докера (определяет, что будет поддерживать в докере)
    container_name: spark-master # имя контейнера
    depends_on: # зависимости, без которых контейнер не будет создан
      - namenode # ждём создания сервиса namenode
      - datanode_1 # ждём создания сервиса datanode_1
    ports: # порты, с которыми будет работать сервис (для обращения к сервису за пределами контейнера с помощью перенаправления указанных портов на порт компьютера (не докера))
      # формат записи <порт компьютера>:<порт контейнера>
      - "8080:8080" # порт для связи с localhost (http://localhost:8080/)
      - "7077:7077" # для связи со spark-worker_ами
      - "4040:4040" # для связи с Spark UI
    environment: # переменные окружения для контейнера (разделитель — ',', а не '/')
      - INIT_DAEMON_STEP=setup_spark
    env_file: # файл с переменными окружения, что будут использоваться в контейнере
      - ./hadoop.env # путь до файла

  spark-worker-1:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: spark-worker-1
    depends_on: # зависимости, без которых контейнер не будет создан
      - spark-master # ждём создания сервиса spark-master
    ports: # порты, с которыми будет работать сервис (для обращения к сервису за пределами контейнера с помощью перенаправления указанных портов на порт компьютера (не докера))
      # формат записи <порт компьютера>:<порт контейнера>
      - "8081:8081"
    environment: # переменные окружения для контейнера (разделитель — ',', а не '/')
      - "SPARK_MASTER=spark://spark-master:7077" # связь со spark-master контейнером
    env_file: # файл с переменными окружения, что будут использоваться в контейнере
      - ./hadoop.env # путь до файла
  
volumes: # создаваемые тома
  hadoop: # имя тома